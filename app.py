import os
from pathlib import Path
from datetime import datetime
import json
import numpy as np
import pandas as pd
import streamlit as st
import xgboost as xgb
import shap
from openai import OpenAI

# -------------------------------
# ê³ ì • ì„¤ì •(ì‚¬ì´ë“œë°” ì…ë ¥ ì œê±° ë²„ì „)
# -------------------------------
st.set_page_config(page_title="Extubation Prediction Demo", layout="wide")

OPENAI_API_KEY = st.secrets.get("OPENAI_API_KEY", None)
OPENAI_BASE_URL = st.secrets.get("OPENAI_BASE_URL", None)

# LLM ì‚¬ìš© ì—¬ë¶€ì™€ ëª¨ë¸ëª…/ê²½ë¡œë¥¼ ì½”ë“œì—ì„œ ê³ ì •
USE_LLM = True   # secretsì— í‚¤ê°€ ì—†ìœ¼ë©´ ìë™ Fallback
FIXED_TAGGING_MODEL = "gpt-4o-mini"        # ì‚¬ë‚´ ê²Œì´íŠ¸ì›¨ì´ ì“°ë©´ ê±°ê¸°ì„œ ì§€ì›í•˜ëŠ” ì´ë¦„ìœ¼ë¡œ êµì²´
FIXED_GENERATION_MODEL = "gpt-4o-mini"
CHAT_MODEL = "gpt-4o-mini"                 # ì‚¬ì´ë“œë°” ì±„íŒ…ìš©
FIXED_MODEL_PATH = "./models/xgboost_model.json"

# -------------------------------
# ìœ í‹¸ / ìƒìˆ˜
# -------------------------------
REQUIRED_FEATURES = [
    'AGE', 'SEX', 'BMI', 'VENT_DUR', 'CHF', 'CVD', 'CPD', 'CKD', 'CLD',
    'DM', 'ECMO', 'CRRT', 'MAP', 'HR', 'RR', 'BT', 'SPO2', 'GCS', 'PH',
    'PACO2', 'PAO2', 'HCO3', 'LACTATE', 'WBC', 'HB', 'PLT', 'SODIUM',
    'POTASSIUM', 'CHLORIDE', 'BUN', 'CR', 'PT', 'FIO2', 'PEEP', 'PPLAT', 'TV'
]

# ì˜ˆì‹œ ì¼€ì´ìŠ¤ 1/2/3
EXAMPLE_CASES = {
    "ì¼€ì´ìŠ¤ 1": {'AGE': 60.0,'SEX': 0.0,'BMI': 31.49090228,'VENT_DUR': 24.88333333,'CHF': 0.0,'CVD': 1.0,'CPD': 0.0,'CKD': 0.0,'CLD': 0.0,'DM': 1.0,'ECMO': 0.0,'CRRT': 0.0,'MAP': 65.0,'HR': 86.0,'RR': 20.0,'BT': 36.5,'SPO2': 95.0,'GCS': 9.0,'PH': 7.41,'PACO2': 40.0,'PAO2': 136.0,'HCO3': 23.0,'LACTATE': 1.8,'WBC': 13.3,'HB': 11.2,'PLT': 166.0,'SODIUM': 138.0,'POTASSIUM': 4.1,'CHLORIDE': 105.0,'BUN': 10.0,'CR': 0.7,'PT': 12.2,'FIO2': 40.0,'PEEP': 5.0,'PPLAT': 21.0,'TV': 546.0},
    "ì¼€ì´ìŠ¤ 2": {'AGE': 72.0,'SEX': 1.0,'BMI': 27.3,'VENT_DUR': 72.0,'CHF': 1.0,'CVD': 0.0,'CPD': 1.0,'CKD': 0.0,'CLD': 0.0,'DM': 0.0,'ECMO': 0.0,'CRRT': 0.0,'MAP': 58.0,'HR': 128.0,'RR': 28.0,'BT': 38.4,'SPO2': 88.0,'GCS': 8.0,'PH': 7.32,'PACO2': 50.0,'PAO2': 70.0,'HCO3': 24.0,'LACTATE': 3.2,'WBC': 18.5,'HB': 10.1,'PLT': 140.0,'SODIUM': 136.0,'POTASSIUM': 4.8,'CHLORIDE': 104.0,'BUN': 26.0,'CR': 1.2,'PT': 14.0,'FIO2': 60.0,'PEEP': 8.0,'PPLAT': 28.0,'TV': 420.0},
    "ì¼€ì´ìŠ¤ 3": {'AGE': 45.0,'SEX': 1.0,'BMI': 33.8,'VENT_DUR': 12.0,'CHF': 0.0,'CVD': 0.0,'CPD': 0.0,'CKD': 0.0,'CLD': 0.0,'DM': 0.0,'ECMO': 0.0,'CRRT': 0.0,'MAP': 75.0,'HR': 92.0,'RR': 18.0,'BT': 36.8,'SPO2': 97.0,'GCS': 13.0,'PH': 7.43,'PACO2': 37.0,'PAO2': 120.0,'HCO3': 24.0,'LACTATE': 1.2,'WBC': 9.8,'HB': 12.5,'PLT': 210.0,'SODIUM': 140.0,'POTASSIUM': 3.9,'CHLORIDE': 103.0,'BUN': 12.0,'CR': 0.8,'PT': 12.0,'FIO2': 35.0,'PEEP': 5.0,'PPLAT': 19.0,'TV': 500.0}
}

def build_openai_client():
    if OPENAI_API_KEY is None:
        return None
    if OPENAI_BASE_URL:
        return OpenAI(api_key=OPENAI_API_KEY, base_url=OPENAI_BASE_URL)
    return OpenAI(api_key=OPENAI_API_KEY)

@st.cache_resource(show_spinner=False)
def load_xgb_model(model_path: str = FIXED_MODEL_PATH):
    p = Path(model_path)
    if not p.exists():
        raise FileNotFoundError(f"Model not found at {model_path}.")
    booster = xgb.Booster()
    booster.load_model(str(p))
    return booster

def _df_from_patient_input(patient_input: dict) -> pd.DataFrame:
    df = pd.DataFrame([patient_input])
    df = df[REQUIRED_FEATURES]
    return df

# LLM íƒœê¹… ì‹¤íŒ¨ì‹œ Fallback
def rule_based_ontology(df: pd.DataFrame) -> dict:
    row = df.iloc[0]
    hemo = int((row.get("SPO2", 100) < 90) or (row.get("HR", 80) < 40) or (row.get("HR", 80) > 120))
    resp = int(row.get("SPO2", 100) < 85)
    ob   = int(row.get("BMI", 0) >= 30)
    age  = int(row.get("AGE", 0) >= 65)
    airway = int(ob and resp)
    return {"patients":[{"patient_index":0,"hemodynamic_instability":hemo,"respiratory_distress":resp,"obesity_risk":ob,"age_risk":age,"airway_obstruction_risk":airway}]}

def llm_tag_ontology(client: OpenAI, df: pd.DataFrame) -> dict:
    patient_records = df.to_dict(orient='records')
    prompt = f"""
ë‹¹ì‹ ì€ ì˜ë£Œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ í™˜ì ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ë°œê´€(extubation) ì‹œ ìœ„í—˜ ìš”ì¸ì´ ë  ìˆ˜ ìˆëŠ” ì˜¨í†¨ë¡œì§€ íŠ¹ì„±ì„ íƒœê¹…í•´ì£¼ì„¸ìš”.

í™˜ì ë°ì´í„°:
{json.dumps(patient_records, ensure_ascii=False, indent=2)}

ë‹¤ìŒ íŠ¹ì„±ì„ 0 ë˜ëŠ” 1ë¡œ ë°˜í™˜:
1. hemodynamic_instability
2. respiratory_distress
3. obesity_risk
4. age_risk
5. airway_obstruction_risk

ë°˜ë“œì‹œ ì•„ë˜ JSON ìŠ¤í‚¤ë§ˆë§Œ ë°˜í™˜:
{{
  "patients": [{{"patient_index":0,"hemodynamic_instability":0,"respiratory_distress":0,"obesity_risk":0,"age_risk":0,"airway_obstruction_risk":0}}]
}}
"""
    resp = client.chat.completions.create(
        model=FIXED_TAGGING_MODEL,
        messages=[
            {"role":"system","content":"ì˜ë£Œ ë°ì´í„° ë¶„ì„ ì „ë¬¸ê°€ë¡œì„œ JSONë§Œ ë°˜í™˜í•©ë‹ˆë‹¤."},
            {"role":"user","content":prompt}
        ],
        temperature=0.2,
        response_format={"type":"json_object"}
    )
    return json.loads(resp.choices[0].message.content)

def attach_ontology_features(df: pd.DataFrame, ontology_json: dict):
    feature_names = ["hemodynamic_instability","respiratory_distress","obesity_risk","age_risk","airway_obstruction_risk"]
    for k in feature_names:
        v = ontology_json["patients"][0].get(k, 0)
        df[k] = int(v)
    return df

def run_xgb_predict(booster: xgb.Booster, feature_df: pd.DataFrame):
    dmatrix = xgb.DMatrix(feature_df.values)
    preds = booster.predict(dmatrix)
    p = float(preds[0])
    y = "ìœ„í—˜" if p > 0.5 else "ì•ˆì „"   # â† 0/1 â†’ â€œì•ˆì „/ìœ„í—˜â€ìœ¼ë¡œ ë³€ê²½
    return {"probability": p, "class_label": y}

def compute_shap(booster: xgb.Booster, feature_df: pd.DataFrame):
    dmatrix = xgb.DMatrix(feature_df.values)
    explainer = shap.TreeExplainer(booster)
    shap_values = explainer.shap_values(dmatrix)
    if isinstance(shap_values, list):
        shap_values = shap_values[0]
    sample_vals = shap_values[0]
    names = feature_df.columns.tolist()
    imp_dict = {names[i]: float(sample_vals[i]) for i in range(len(names))}
    top5 = sorted([(k, abs(v)) for k, v in imp_dict.items()], key=lambda x: x[1], reverse=True)[:5]
    return {"shap_values": shap_values, "feature_importance": imp_dict, "top_risk_factors": top5}

def llm_generate_report(client: OpenAI, patient_input: dict, prediction: dict, shap_exp: dict) -> str:
    top_risk_factors = []
    for k, abs_imp in shap_exp["top_risk_factors"]:
        impact_dir = "ìœ„í—˜ë„ ì¦ê°€" if shap_exp["feature_importance"][k] > 0 else "ìœ„í—˜ë„ ê°ì†Œ"
        top_risk_factors.append({"feature_name": k, "importance_score": round(abs_imp, 4), "impact": impact_dir})

    prompt = f"""
ë‹¹ì‹ ì€ ì˜ë£Œì§„ê³¼ í™˜ì ë³´í˜¸ì ì‚¬ì´ì˜ ì†Œí†µì„ ë•ëŠ” ì˜ë£Œ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì•„ë˜ ì¸ê³µì§€ëŠ¥ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë³´í˜¸ìê°€ ì´í•´í•˜ê¸° ì‰¬ìš´ ì„¤ëª… ë ˆí¬íŠ¸ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.

[ì…ë ¥ ë°ì´í„°]
í™˜ì ì •ë³´:
{json.dumps(patient_input, ensure_ascii=False, indent=2)}

AI ì˜ˆì¸¡ ê²°ê³¼:
- ë°œê´€ ì‹¤íŒ¨ í™•ë¥ : {prediction['probability']:.1%}
- ì˜ˆì¸¡ í´ë˜ìŠ¤: {prediction['class_label']} (ì•ˆì „/ìœ„í—˜)

ì£¼ìš” ìœ„í—˜ ìš”ì¸:
{json.dumps(top_risk_factors, ensure_ascii=False, indent=2)}

[ì§€ì¹¨] ë”°ëœ»í•˜ê³  ê³µê°ì ì¸ ì–´ì¡°, ì „ë¬¸ìš©ì–´ë¥¼ ì‰¬ìš´ ë§ë¡œ, ë§ˆí¬ë‹¤ìš´ ê¸ˆì§€, ì„¹ì…˜ ì œëª©ì€ [ì„¹ì…˜ëª…]
"""
    resp = client.chat.completions.create(
        model=FIXED_GENERATION_MODEL,
        messages=[
            {"role":"system","content":"ë‹¹ì‹ ì€ ì˜ë£Œ ì •ë³´ë¥¼ ì¼ë°˜ì¸ì´ ì´í•´í•˜ê¸° ì‰½ê²Œ ì „ë‹¬í•˜ëŠ” ì˜ë£Œ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
            {"role":"user","content":prompt}
        ],
        temperature=0.6
    )
    body = resp.choices[0].message.content.strip()
    header = f"{'='*60}\nê¸°ê³„í™˜ê¸° ë°œê´€ ì•ˆë‚´ë¬¸\n{'='*60}\n\nìƒì„± ì¼ì‹œ: {datetime.now().strftime('%Yë…„ %mì›” %dì¼ %H:%M')}\n\n"
    footer = f"\n\n{'='*60}\në³¸ ì•ˆë‚´ë¬¸ì€ AI ê¸°ë°˜ ì˜ˆì¸¡ ì‹œìŠ¤í…œì„ í™œìš©í•˜ì—¬ ì‘ì„±ë˜ì—ˆìŠµë‹ˆë‹¤.\nìµœì¢… ì˜ë£Œ ê²°ì •ì€ ë‹´ë‹¹ ì˜ë£Œì§„ì˜ ì¢…í•©ì ì¸ íŒë‹¨ì— ë”°ë¼ ì´ë£¨ì–´ì§‘ë‹ˆë‹¤.\nê¶ê¸ˆí•œ ì ì´ë‚˜ ìš°ë ¤ì‚¬í•­ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“  ì˜ë£Œì§„ì—ê²Œ ë¬¸ì˜í•´ ì£¼ì„¸ìš”.\n{'='*60}\n"
    return header + body + footer

def ontology_pretty_table(ontology_json: dict) -> pd.DataFrame:
    """ì˜¨í†¨ë¡œì§€ ê²°ê³¼ë¥¼ ì˜ˆìœ í…Œì´ë¸”(ì•„ì´ì½˜ í¬í•¨)ë¡œ ë³€í™˜"""
    labels = {
        "hemodynamic_instability": "í˜ˆì—­í•™ì  ë¶ˆì•ˆì •",
        "respiratory_distress": "í˜¸í¡ ê³¤ë€",
        "obesity_risk": "ë¹„ë§Œ ìœ„í—˜",
        "age_risk": "ê³ ë ¹ ìœ„í—˜",
        "airway_obstruction_risk": "ê¸°ë„ íì‡„ ìœ„í—˜"
    }
    desc = {
        "hemodynamic_instability": "SpOâ‚‚<90% ë˜ëŠ” ì‹¬ë°• ì´ìƒ",
        "respiratory_distress": "SpOâ‚‚<85%",
        "obesity_risk": "BMIâ‰¥30",
        "age_risk": "ë‚˜ì´â‰¥65ì„¸",
        "airway_obstruction_risk": "ë¹„ë§Œ+í˜¸í¡ê³¤ë€ ë™ì‹œ"
    }
    row = ontology_json["patients"][0]
    rows = []
    for k in labels:
        val = int(row.get(k, 0))
        icon = "âœ…" if val == 1 else "âŒ"
        rows.append({"íŠ¹ì„±": labels[k], "ì„¤ëª…": desc[k], "ì—¬ë¶€": icon})
    return pd.DataFrame(rows)

# -------------------------------
# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
# -------------------------------
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []  # [{role, content}]
if "memory" not in st.session_state:
    st.session_state.memory = {}        # ìµœê·¼ ì˜ˆì¸¡ ì»¨í…ìŠ¤íŠ¸ ì €ì¥

# -------------------------------
# ë©”ì¸ UI
# -------------------------------
st.title("Extubation Prediction Demo (Streamlit)")

# (2) ì¼€ì´ìŠ¤ ì„ íƒ â†’ í¼ ìë™ ì±„ìš°ê¸°
st.subheader("1) ì˜ˆì‹œ ì¼€ì´ìŠ¤ ì„ íƒ")
selected_case = st.selectbox("ì˜ˆì‹œ ì¼€ì´ìŠ¤", list(EXAMPLE_CASES.keys()), index=0)
case_vals = EXAMPLE_CASES[selected_case]

# í¼ ì…ë ¥ê°’ì„ ì„¸ì…˜ì— ë°˜ì˜
for k in REQUIRED_FEATURES:
    if f"val_{k}" not in st.session_state:
        st.session_state[f"val_{k}"] = case_vals.get(k, np.nan)

# ì¼€ì´ìŠ¤ ì„ íƒì´ ë°”ë€Œë©´ í•´ë‹¹ ê°’ìœ¼ë¡œ ì´ˆê¸°í™”
def apply_case(vals: dict):
    for k, v in vals.items():
        st.session_state[f"val_{k}"] = v

if st.button("ì´ ì¼€ì´ìŠ¤ ê°’ ë¶ˆëŸ¬ì˜¤ê¸°"):
    apply_case(EXAMPLE_CASES[selected_case])
    st.success(f"{selected_case} ê°’ì´ ì…ë ¥ í¼ì— ë°˜ì˜ë˜ì—ˆìŠµë‹ˆë‹¤.")

# ì…ë ¥ í¼
st.subheader("2) í™˜ì ì…ë ¥")
colA, colB, colC, colD, colE = st.columns(5)

with colA:
    st.session_state["val_AGE"] = st.number_input("AGE", 0, 120, int(st.session_state["val_AGE"]))
    st.session_state["val_SEX"] = st.selectbox("SEX (0=female,1=male)", [0,1], index=int(st.session_state["val_SEX"]))
    st.session_state["val_BMI"] = st.number_input("BMI", 0.0, 80.0, float(st.session_state["val_BMI"]))
    st.session_state["val_VENT_DUR"] = st.number_input("VENT_DUR (hr)", 0.0, 1000.0, float(st.session_state["val_VENT_DUR"]))
    st.session_state["val_CHF"] = st.selectbox("CHF", [0,1], index=int(st.session_state["val_CHF"]))
    st.session_state["val_CVD"] = st.selectbox("CVD", [0,1], index=int(st.session_state["val_CVD"]))
    st.session_state["val_CPD"] = st.selectbox("CPD", [0,1], index=int(st.session_state["val_CPD"]))
    st.session_state["val_CKD"] = st.selectbox("CKD", [0,1], index=int(st.session_state["val_CKD"]))

with colB:
    st.session_state["val_CLD"] = st.selectbox("CLD", [0,1], index=int(st.session_state["val_CLD"]))
    st.session_state["val_DM"] = st.selectbox("DM", [0,1], index=int(st.session_state["val_DM"]))
    st.session_state["val_ECMO"] = st.selectbox("ECMO", [0,1], index=int(st.session_state["val_ECMO"]))
    st.session_state["val_CRRT"] = st.selectbox("CRRT", [0,1], index=int(st.session_state["val_CRRT"]))
    st.session_state["val_MAP"] = st.number_input("MAP", 0.0, 200.0, float(st.session_state["val_MAP"]))
    st.session_state["val_HR"] = st.number_input("HR", 0.0, 220.0, float(st.session_state["val_HR"]))
    st.session_state["val_RR"] = st.number_input("RR", 0.0, 80.0, float(st.session_state["val_RR"]))
    st.session_state["val_BT"] = st.number_input("BT (Â°C)", value=float(case_vals.get("BT", 36.5)))

with colC:
    st.session_state["val_SPO2"] = st.number_input("SPO2 (%)", 0.0, 100.0, float(st.session_state["val_SPO2"]))
    st.session_state["val_GCS"] = st.number_input("GCS", 3.0, 15.0, float(st.session_state["val_GCS"]))
    st.session_state["val_PH"] = st.number_input("pH", 6.8, 7.8, float(st.session_state["val_PH"]), step=0.01)
    st.session_state["val_PACO2"] = st.number_input("PaCO2", 10.0, 120.0, float(st.session_state["val_PACO2"]))
    st.session_state["val_PAO2"] = st.number_input("PaO2", 10.0, 600.0, float(st.session_state["val_PAO2"]))
    st.session_state["val_HCO3"] = st.number_input("HCO3-", 5.0, 45.0, float(st.session_state["val_HCO3"]))
    st.session_state["val_LACTATE"] = st.number_input("Lactate", 0.0, 20.0, float(st.session_state["val_LACTATE"]))

with colD:
    st.session_state["val_WBC"] = st.number_input("WBC", 0.0, 100.0, float(st.session_state["val_WBC"]))
    st.session_state["val_HB"] = st.number_input("Hb", 0.0, 25.0, float(st.session_state["val_HB"]))
    st.session_state["val_PLT"] = st.number_input("PLT", 0.0, 1000.0, float(st.session_state["val_PLT"]))
    st.session_state["val_SODIUM"] = st.number_input("Na", 100.0, 180.0, float(st.session_state["val_SODIUM"]))
    st.session_state["val_POTASSIUM"] = st.number_input("K", 1.5, 8.0, float(st.session_state["val_POTASSIUM"]))
    st.session_state["val_CHLORIDE"] = st.number_input("Cl", 70.0, 140.0, float(st.session_state["val_CHLORIDE"]))
    st.session_state["val_BUN"] = st.number_input("BUN", 0.0, 200.0, float(st.session_state["val_BUN"]))

with colE:
    st.session_state["val_CR"] = st.number_input("Cr", 0.0, 20.0, float(st.session_state["val_CR"]))
    st.session_state["val_PT"] = st.number_input("PT", 5.0, 30.0, float(st.session_state["val_PT"]))
    st.session_state["val_FIO2"] = st.number_input("FiO2 (%)", 21.0, 100.0, float(st.session_state["val_FIO2"]))
    st.session_state["val_PEEP"] = st.number_input("PEEP", 0.0, 30.0, float(st.session_state["val_PEEP"]))
    st.session_state["val_PPLAT"] = st.number_input("Pplat", 0.0, 60.0, float(st.session_state["val_PPLAT"]))
    st.session_state["val_TV"] = st.number_input("TV (mL)", 0.0, 1500.0, float(st.session_state["val_TV"]))

# ì‹¤í–‰ ë²„íŠ¼
st.subheader("3) ì‹¤í–‰")
run = st.button("ì˜ˆì¸¡ ì‹¤í–‰")

if run:
    # ì…ë ¥ ë”•ì…”ë„ˆë¦¬ ë§Œë“¤ê¸°
    patient_input = {k: float(st.session_state[f"val_{k}"]) if not np.isnan(st.session_state[f"val_{k}"]) else np.nan
                     for k in REQUIRED_FEATURES}

    # 1) ì…ë ¥ â†’ DF
    df = _df_from_patient_input(patient_input)

    # 2) ì˜¨í†¨ë¡œì§€ íƒœê¹…
    with st.spinner("ì˜¨í†¨ë¡œì§€ íƒœê¹… ì¤‘..."):
        try:
            if USE_LLM and OPENAI_API_KEY:
                client = build_openai_client()
                ontology_json = llm_tag_ontology(client, df)
            else:
                ontology_json = rule_based_ontology(df)
        except Exception as e:
            st.warning(f"LLM íƒœê¹… ì‹¤íŒ¨. ë£° ê¸°ë°˜ìœ¼ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤. ({e})")
            ontology_json = rule_based_ontology(df)

    feature_df = attach_ontology_features(df.copy(), ontology_json)

    # 3) ëª¨ë¸ ë¡œë“œ & ì˜ˆì¸¡
    with st.spinner("XGBoost ì˜ˆì¸¡ ì¤‘..."):
        try:
            booster = load_xgb_model(FIXED_MODEL_PATH)
            pred = run_xgb_predict(booster, feature_df)
        except Exception as e:
            st.error(f"ì˜ˆì¸¡ ì˜¤ë¥˜: {e}")
            st.stop()

    # 4) SHAP
    with st.spinner("SHAP ê³„ì‚° ì¤‘..."):
        try:
            shap_exp = compute_shap(booster, feature_df)
        except Exception as e:
            st.warning(f"SHAP ê³„ì‚° ì‹¤íŒ¨: {e}")
            shap_exp = {"feature_importance": {}, "top_risk_factors": []}

    # 5) ë ˆí¬íŠ¸
    report_text = None
    if USE_LLM and OPENAI_API_KEY:
        with st.spinner("ì„¤ëª… ë ˆí¬íŠ¸ ìƒì„± ì¤‘..."):
            try:
                client = build_openai_client()
                report_text = llm_generate_report(client, patient_input, pred, shap_exp)
            except Exception as e:
                st.warning(f"ë ˆí¬íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
                report_text = None

    # ê²°ê³¼ í‘œì‹œ
    st.success("ì™„ë£Œ!")

    col1, col2 = st.columns([1,1])
    with col1:
        st.markdown("### ì˜ˆì¸¡ ê²°ê³¼")
        st.metric("ë°œê´€ ì‹¤íŒ¨ í™•ë¥ ", f"{pred['probability']*100:.1f}%")
        st.metric("ì˜ˆì¸¡ í´ë˜ìŠ¤", pred['class_label"])  # â€œì•ˆì „/ìœ„í—˜â€

        st.markdown("### ì˜¨í†¨ë¡œì§€ íƒœê¹… ê²°ê³¼")
        pretty_df = ontology_pretty_table(ontology_json)
        st.dataframe(pretty_df, hide_index=True, use_container_width=True)

    with col2:
        st.markdown("### ìƒìœ„ ìœ„í—˜ ìš”ì¸ (SHAP | ì ˆëŒ€ê°’ Top 5)")
        if "top_risk_factors" in shap_exp and shap_exp["top_risk_factors"]:
            rows = []
            for name, abs_imp in shap_exp["top_risk_factors"]:
                sign = shap_exp["feature_importance"].get(name, 0.0)
                direction = "â†‘ ìœ„í—˜ ì¦ê°€" if sign > 0 else "â†“ ìœ„í—˜ ê°ì†Œ"
                rows.append({"feature": name, "abs_importance": round(abs_imp, 5), "direction": direction})
            st.dataframe(pd.DataFrame(rows), hide_index=True, use_container_width=True)
        else:
            st.write("ê³„ì‚°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    # (5) ë³´í˜¸ì ë ˆí¬íŠ¸: í† ê¸€ë¡œ ì˜¨ì˜¤í”„
    st.markdown("### ë³´í˜¸ì ì„¤ëª…ìš© ë ˆí¬íŠ¸")
    show_report = st.toggle("ë ˆí¬íŠ¸ ë³´ê¸°", value=False)
    if show_report and report_text:
        st.text(report_text)
    elif show_report and not report_text:
        st.info("ë ˆí¬íŠ¸ê°€ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    st.markdown("### ëª¨ë¸ ì…ë ¥ ì „ì²´ Feature (ì¶”ë¡  ì‹œ ì‚¬ìš©)")
    st.dataframe(feature_df, use_container_width=True)

    # ì±„íŒ… ë©”ëª¨ë¦¬ì— ì €ì¥í•  ì»¨í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸
    st.session_state.memory = {
        "timestamp": datetime.now().isoformat(timespec="seconds"),
        "selected_case": selected_case,
        "patient_input": patient_input,
        "prediction": pred,
        "shap_top": shap_exp.get("top_risk_factors", []),
    }

# -------------------------------
# ì‚¬ì´ë“œë°”: ì±„íŒ… (ëª¨ë¸/ê²½ë¡œ ì…ë ¥ ëŒ€ì‹ )
# -------------------------------
with st.sidebar:
    st.header("ğŸ’¬ ëŒ€í™”")
    if OPENAI_API_KEY is None:
        st.caption("OpenAI í‚¤ê°€ ì—†ì–´ì„œ ì±„íŒ…ì€ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤. (Secretsì— OPENAI_API_KEY ì¶”ê°€)")
    else:
        # ìµœê·¼ ì˜ˆì¸¡ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì‹œìŠ¤í…œ ë©”ì‹œì§€ë¡œ ì£¼ì…
        context_blob = json.dumps(st.session_state.memory, ensure_ascii=False, indent=2) if st.session_state.memory else "ìµœê·¼ ì˜ˆì¸¡ ì»¨í…ìŠ¤íŠ¸ ì—†ìŒ."
        system_msg = (
            "ë‹¹ì‹ ì€ ì„ìƒì˜ì™€ í˜‘ì—…í•˜ëŠ” ë°ì´í„°ì‚¬ì´ì–¸ìŠ¤ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. "
            "ì•„ë˜ 'ìµœê·¼ ì˜ˆì¸¡ ì»¨í…ìŠ¤íŠ¸'ë¥¼ ì°¸ê³ í•˜ì—¬ ê°„ê²°í•˜ê³  ì •í™•í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.\n\n"
            f"[ìµœê·¼ ì˜ˆì¸¡ ì»¨í…ìŠ¤íŠ¸]\n{context_blob}"
        )

        # ê¸°ì¡´ ëŒ€í™” í‘œì‹œ
        for m in st.session_state.chat_history:
            with st.chat_message(m["role"]):
                st.markdown(m["content"])

        user_msg = st.chat_input("ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”")
        if user_msg:
            st.session_state.chat_history.append({"role":"user","content":user_msg})
            with st.chat_message("user"):
                st.markdown(user_msg)

            try:
                client = build_openai_client()
                messages = [{"role":"system","content":system_msg}] + st.session_state.chat_history[-20:]  # ìµœê·¼ 20í„´
                resp = client.chat.completions.create(
                    model=CHAT_MODEL,
                    messages=messages,
                    temperature=0.3
                )
                bot_text = resp.choices[0].message.content.strip()
            except Exception as e:
                bot_text = f"(ì˜¤ë¥˜) {e}"

            st.session_state.chat_history.append({"role":"assistant","content":bot_text})
            with st.chat_message("assistant"):
                st.markdown(bot_text)