import os
from pathlib import Path
from datetime import datetime
import json
import numpy as np
import pandas as pd
import streamlit as st
import xgboost as xgb
import shap
from openai import OpenAI

# -------------------------------
# ê³ ì • ì„¤ì •(ì‚¬ì´ë“œë°” ì…ë ¥ ì œê±° ë²„ì „)
# -------------------------------
st.set_page_config(page_title="Extubation Prediction Demo", layout="wide")

OPENAI_API_KEY = st.secrets.get("OPENAI_API_KEY", None)
OPENAI_BASE_URL = st.secrets.get("OPENAI_BASE_URL", None)

# LLM ì‚¬ìš© ì—¬ë¶€ì™€ ëª¨ë¸ëª…/ê²½ë¡œë¥¼ ì½”ë“œì—ì„œ ê³ ì •
USE_LLM = True   # secretsì— í‚¤ê°€ ì—†ìœ¼ë©´ ìë™ Fallback
FIXED_TAGGING_MODEL = "gpt-4o-mini"        # ì‚¬ë‚´ ê²Œì´íŠ¸ì›¨ì´ ì“°ë©´ ê±°ê¸°ì„œ ì§€ì›í•˜ëŠ” ì´ë¦„ìœ¼ë¡œ êµì²´
FIXED_GENERATION_MODEL = "gpt-4o-mini"
CHAT_MODEL = "gpt-4o-mini"                 # ì‚¬ì´ë“œë°” ì±„íŒ…ìš©
FIXED_MODEL_PATH = "./models/xgboost_model.json"

# -------------------------------
# ìœ í‹¸ / ìƒìˆ˜
# -------------------------------
REQUIRED_FEATURES = [
    'AGE', 'SEX', 'BMI', 'VENT_DUR', 'CHF', 'CVD', 'CPD', 'CKD', 'CLD',
    'DM', 'ECMO', 'CRRT', 'MAP', 'HR', 'RR', 'BT', 'SPO2', 'GCS', 'PH',
    'PACO2', 'PAO2', 'HCO3', 'LACTATE', 'WBC', 'HB', 'PLT', 'SODIUM',
    'POTASSIUM', 'CHLORIDE', 'BUN', 'CR', 'PT', 'FIO2', 'PEEP', 'PPLAT', 'TV'
]

# ì˜ˆì‹œ ì¼€ì´ìŠ¤ 1/2/3
EXAMPLE_CASES = {
    "ì¼€ì´ìŠ¤ 1": {'AGE': 60.0,'SEX': 0.0,'BMI': 31.49090228,'VENT_DUR': 24.88333333,'CHF': 0.0,'CVD': 1.0,'CPD': 0.0,'CKD': 0.0,'CLD': 0.0,'DM': 1.0,'ECMO': 0.0,'CRRT': 0.0,'MAP': 65.0,'HR': 86.0,'RR': 20.0,'BT': 36.5,'SPO2': 95.0,'GCS': 9.0,'PH': 7.41,'PACO2': 40.0,'PAO2': 136.0,'HCO3': 23.0,'LACTATE': 1.8,'WBC': 13.3,'HB': 11.2,'PLT': 166.0,'SODIUM': 138.0,'POTASSIUM': 4.1,'CHLORIDE': 105.0,'BUN': 10.0,'CR': 0.7,'PT': 12.2,'FIO2': 40.0,'PEEP': 5.0,'PPLAT': 21.0,'TV': 546.0},
    "ì¼€ì´ìŠ¤ 2": {'AGE': 72.0,'SEX': 1.0,'BMI': 27.3,'VENT_DUR': 72.0,'CHF': 1.0,'CVD': 0.0,'CPD': 1.0,'CKD': 0.0,'CLD': 0.0,'DM': 0.0,'ECMO': 0.0,'CRRT': 0.0,'MAP': 58.0,'HR': 128.0,'RR': 28.0,'BT': 38.4,'SPO2': 88.0,'GCS': 8.0,'PH': 7.32,'PACO2': 50.0,'PAO2': 70.0,'HCO3': 24.0,'LACTATE': 3.2,'WBC': 18.5,'HB': 10.1,'PLT': 140.0,'SODIUM': 136.0,'POTASSIUM': 4.8,'CHLORIDE': 104.0,'BUN': 26.0,'CR': 1.2,'PT': 14.0,'FIO2': 60.0,'PEEP': 8.0,'PPLAT': 28.0,'TV': 420.0},
    "ì¼€ì´ìŠ¤ 3": {'AGE': 45.0,'SEX': 1.0,'BMI': 33.8,'VENT_DUR': 12.0,'CHF': 0.0,'CVD': 0.0,'CPD': 0.0,'CKD': 0.0,'CLD': 0.0,'DM': 0.0,'ECMO': 0.0,'CRRT': 0.0,'MAP': 75.0,'HR': 92.0,'RR': 18.0,'BT': 36.8,'SPO2': 97.0,'GCS': 13.0,'PH': 7.43,'PACO2': 37.0,'PAO2': 120.0,'HCO3': 24.0,'LACTATE': 1.2,'WBC': 9.8,'HB': 12.5,'PLT': 210.0,'SODIUM': 140.0,'POTASSIUM': 3.9,'CHLORIDE': 103.0,'BUN': 12.0,'CR': 0.8,'PT': 12.0,'FIO2': 35.0,'PEEP': 5.0,'PPLAT': 19.0,'TV': 500.0}
}

def build_openai_client():
    if OPENAI_API_KEY is None:
        return None
    if OPENAI_BASE_URL:
        return OpenAI(api_key=OPENAI_API_KEY, base_url=OPENAI_BASE_URL)
    return OpenAI(api_key=OPENAI_API_KEY)

@st.cache_resource(show_spinner=False)
def load_xgb_model(model_path: str = FIXED_MODEL_PATH):
    p = Path(model_path)
    if not p.exists():
        raise FileNotFoundError(f"Model not found at {model_path}.")
    booster = xgb.Booster()
    booster.load_model(str(p))
    return booster

def _df_from_patient_input(patient_input: dict) -> pd.DataFrame:
    df = pd.DataFrame([patient_input])
    df = df[REQUIRED_FEATURES]
    return df

# -------------------------------
# ì˜¨í†¨ë¡œì§€ ê´€ë ¨ í—¬í¼
# -------------------------------
def _ontology_label_maps():
    labels = {
        "hemodynamic_instability": "í˜ˆì—­í•™ì  ë¶ˆì•ˆì •",
        "respiratory_distress": "í˜¸í¡ ê³¤ë€",
        "obesity_risk": "ë¹„ë§Œ ìœ„í—˜",
        "age_risk": "ê³ ë ¹ ìœ„í—˜",
        "airway_obstruction_risk": "ê¸°ë„ íì‡„ ìœ„í—˜"
    }
    desc = {
        "hemodynamic_instability": "SpOâ‚‚<90% ë˜ëŠ” ì‹¬ë°• ì´ìƒ",
        "respiratory_distress": "SpOâ‚‚<85%",
        "obesity_risk": "BMIâ‰¥30",
        "age_risk": "ë‚˜ì´â‰¥65ì„¸",
        "airway_obstruction_risk": "ë¹„ë§Œ+í˜¸í¡ê³¤ë€ ë™ì‹œ"
    }
    return labels, desc

def summarize_ontology_for_report(ontology_json: dict):
    """ë ˆí¬íŠ¸ìš©: 1(í•´ë‹¹)ì¸ ì˜¨í†¨ë¡œì§€ í•­ëª©ê³¼ 0(ë¹„í•´ë‹¹) í•­ëª©ì„ êµ¬ë¶„ ì •ë¦¬"""
    labels, desc = _ontology_label_maps()
    row = ontology_json["patients"][0]
    positives, negatives = [], []
    for k in labels:
        item = {
            "key": k,
            "name": labels[k],
            "rule": desc[k],
            "value": int(row.get(k, 0))
        }
        (positives if item["value"] == 1 else negatives).append(item)
    return positives, negatives

def ontology_pretty_table(ontology_json: dict) -> pd.DataFrame:
    """ì˜¨í†¨ë¡œì§€ ê²°ê³¼ë¥¼ ì˜ˆìœ í…Œì´ë¸”(ì•„ì´ì½˜ í¬í•¨)ë¡œ ë³€í™˜"""
    labels, desc = _ontology_label_maps()
    row = ontology_json["patients"][0]
    rows = []
    for k in labels:
        val = int(row.get(k, 0))
        icon = "âœ…" if val == 1 else "âŒ"
        rows.append({"íŠ¹ì„±": labels[k], "ì„¤ëª…": desc[k], "ì—¬ë¶€": icon})
    return pd.DataFrame(rows)

# -------------------------------
# LLM íƒœê¹… ë° ë£° ê¸°ë°˜ Fallback
# -------------------------------
def rule_based_ontology(df: pd.DataFrame) -> dict:
    row = df.iloc[0]
    hemo = int((row.get("SPO2", 100) < 90) or (row.get("HR", 80) < 40) or (row.get("HR", 80) > 120))
    resp = int(row.get("SPO2", 100) < 85)
    ob   = int(row.get("BMI", 0) >= 30)
    age  = int(row.get("AGE", 0) >= 65)
    airway = int(ob and resp)
    return {"patients":[{"patient_index":0,"hemodynamic_instability":hemo,"respiratory_distress":resp,"obesity_risk":ob,"age_risk":age,"airway_obstruction_risk":airway}]}

def llm_tag_ontology(client: OpenAI, df: pd.DataFrame) -> dict:
    patient_records = df.to_dict(orient='records')
    prompt = f"""
ë‹¹ì‹ ì€ ì˜ë£Œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ í™˜ì ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ë°œê´€(extubation) ì‹œ ìœ„í—˜ ìš”ì¸ì´ ë  ìˆ˜ ìˆëŠ” ì˜¨í†¨ë¡œì§€ íŠ¹ì„±ì„ íƒœê¹…í•´ì£¼ì„¸ìš”.

í™˜ì ë°ì´í„°:
{json.dumps(patient_records, ensure_ascii=False, indent=2)}

ë‹¤ìŒ íŠ¹ì„±ì„ 0 ë˜ëŠ” 1ë¡œ ë°˜í™˜:
1. hemodynamic_instability
2. respiratory_distress
3. obesity_risk
4. age_risk
5. airway_obstruction_risk

ë°˜ë“œì‹œ ì•„ë˜ JSON ìŠ¤í‚¤ë§ˆë§Œ ë°˜í™˜:
{{
  "patients": [{{"patient_index":0,"hemodynamic_instability":0,"respiratory_distress":0,"obesity_risk":0,"age_risk":0,"airway_obstruction_risk":0}}]
}}
"""
    resp = client.chat.completions.create(
        model=FIXED_TAGGING_MODEL,
        messages=[
            {"role":"system","content":"ì˜ë£Œ ë°ì´í„° ë¶„ì„ ì „ë¬¸ê°€ë¡œì„œ JSONë§Œ ë°˜í™˜í•©ë‹ˆë‹¤."},
            {"role":"user","content":prompt}
        ],
        temperature=0.2,
        response_format={"type":"json_object"}
    )
    return json.loads(resp.choices[0].message.content)

def attach_ontology_features(df: pd.DataFrame, ontology_json: dict):
    feature_names = ["hemodynamic_instability","respiratory_distress","obesity_risk","age_risk","airway_obstruction_risk"]
    for k in feature_names:
        v = ontology_json["patients"][0].get(k, 0)
        df[k] = int(v)
    return df

# -------------------------------
# SHAP ìš”ì•½ í—¬í¼
# -------------------------------
def summarize_shap_for_report(shap_exp: dict, top_k: int = 5):
    """
    ë ˆí¬íŠ¸ìš©: SHAPì—ì„œ ì˜í–¥ì´ í° ìƒìœ„/í•˜ìœ„ ìš”ì¸ ë¦¬ìŠ¤íŠ¸ë¥¼ ê°ê° ì¶”ë¦½ë‹ˆë‹¤.
    ìƒìœ„: |ê°’| í° ìˆœ, sign>0ì´ë©´ ìœ„í—˜â†‘, sign<0ì´ë©´ ìœ„í—˜â†“
    """
    fi = shap_exp.get("feature_importance", {}) or {}
    if not fi:
        return [], []
    triples = [(name, abs(val), val) for name, val in fi.items()]
    triples.sort(key=lambda x: x[1], reverse=True)
    top = [{"feature": n, "abs_importance": round(a, 5), "direction": ("ìœ„í—˜ ì¦ê°€" if s > 0 else "ìœ„í—˜ ê°ì†Œ")}
           for (n, a, s) in triples[:top_k]]
    bottom = [{"feature": n, "abs_importance": round(a, 5), "direction": ("ìœ„í—˜ ì¦ê°€" if s > 0 else "ìœ„í—˜ ê°ì†Œ")}
              for (n, a, s) in triples[-top_k:]]
    return top, bottom

# -------------------------------
# ì˜ˆì¸¡/SHAP/ë ˆí¬íŠ¸
# -------------------------------
def run_xgb_predict(booster: xgb.Booster, feature_df: pd.DataFrame):
    dmatrix = xgb.DMatrix(feature_df.values)
    preds = booster.predict(dmatrix)
    p = float(preds[0])
    y = "ìœ„í—˜" if p > 0.5 else "ì•ˆì „"   # â† 0/1 â†’ â€œì•ˆì „/ìœ„í—˜â€ìœ¼ë¡œ ë³€ê²½
    return {"probability": p, "class_label": y}

def compute_shap(booster: xgb.Booster, feature_df: pd.DataFrame):
    dmatrix = xgb.DMatrix(feature_df.values)
    explainer = shap.TreeExplainer(booster)
    shap_values = explainer.shap_values(dmatrix)
    if isinstance(shap_values, list):
        shap_values = shap_values[0]
    sample_vals = shap_values[0]
    names = feature_df.columns.tolist()
    imp_dict = {names[i]: float(sample_vals[i]) for i in range(len(names))}
    top5 = sorted([(k, abs(v)) for k, v in imp_dict.items()], key=lambda x: x[1], reverse=True)[:5]
    return {"shap_values": shap_values, "feature_importance": imp_dict, "top_risk_factors": top5}

def llm_generate_report(client: OpenAI, patient_input: dict, prediction: dict, shap_exp: dict, ontology_json: dict) -> str:
    """
    ë³´í˜¸ì ì„¤ëª… ë ˆí¬íŠ¸ë¥¼ SHAP + ì˜¨í†¨ë¡œì§€ ì–‘ìª½ ê·¼ê±°ë¡œ í’ë¶€í•˜ê²Œ ìƒì„±.
    - ì˜ˆì¸¡ í´ë˜ìŠ¤(ì•ˆì „/ìœ„í—˜)ì— ë”°ë¼ í†¤ì„ ìë™ ì¡°ì ˆ
    - ì˜¨í†¨ë¡œì§€ì—ì„œ 1ì¸ í•­ëª©ì€ ë°˜ë“œì‹œ ë³¸ë¬¸ì— ë°˜ì˜
    - SHAP ìƒìœ„ ìš”ì¸ì€ 'ì™œ ê·¸ëŸ° ì˜ˆì¸¡ì´ ë‚˜ì™”ëŠ”ì§€'ë¥¼ ì„¤ëª…í•˜ëŠ” ê·¼ê±°ë¡œ ì‚¬ìš©
    """
    # ì˜¨í†¨ë¡œì§€ ìš”ì•½(1/0 ë¶„ë¦¬)
    ont_pos, ont_neg = summarize_ontology_for_report(ontology_json)
    # SHAP ìƒÂ·í•˜ìœ„ ìš”ì•½
    shap_top, _ = summarize_shap_for_report(shap_exp, top_k=5)

    # í”„ë¡¬í”„íŠ¸ì— ë„£ì„ JSON/ëª©ë¡(LLMì´ ì •í™•íˆ ì°¸ê³ í•˜ë„ë¡)
    ont_pos_for_llm = [{"name": x["name"], "rule": x["rule"]} for x in ont_pos] or [{"name": "í•´ë‹¹ í•­ëª© ì—†ìŒ", "rule": ""}]
    ont_neg_for_llm = [{"name": x["name"], "rule": x["rule"]} for x in ont_neg]
    shap_top_for_llm = shap_top or [{"feature": "í•´ë‹¹ ì—†ìŒ", "abs_importance": 0.0, "direction": ""}]

    # í´ë˜ìŠ¤ì— ë”°ë¥¸ í†¤ ê°€ì´ë“œ
    cls_label = prediction.get("class_label", "ì•ˆì „")

    prompt = f"""
ë‹¹ì‹ ì€ ì˜ë£Œì§„ê³¼ í™˜ì ë³´í˜¸ì ì‚¬ì´ì˜ ì†Œí†µì„ ë•ëŠ” ì˜ë£Œ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì•„ë˜ 'ëª¨ë¸ ì˜ˆì¸¡', 'ì˜¨í†¨ë¡œì§€ íŒë‹¨ ê²°ê³¼', 'SHAP ì¤‘ìš” ìš”ì¸'ì„ ëª¨ë‘ ì°¸ê³ í•˜ì—¬,
ë³´í˜¸ìê°€ ì´í•´í•˜ê¸° ì‰¬ìš´ ì„¤ëª… ë ˆí¬íŠ¸ë¥¼ ì‘ì„±í•˜ì„¸ìš”.

[ëª¨ë¸ ì˜ˆì¸¡]
- ë°œê´€ ì‹¤íŒ¨ í™•ë¥ : {prediction['probability']:.1%}
- ì˜ˆì¸¡ í´ë˜ìŠ¤(ì•ˆì „/ìœ„í—˜): {cls_label}

[ì˜¨í†¨ë¡œì§€ íŒë‹¨ ê²°ê³¼]
- ì´ í™˜ìì—ê²Œ ì‹¤ì œ í•´ë‹¹ëœ í•­ëª©(ê°’=1): {json.dumps(ont_pos_for_llm, ensure_ascii=False)}
- í•´ë‹¹ë˜ì§€ ì•Šì€ í•­ëª©(ê°’=0): {json.dumps(ont_neg_for_llm, ensure_ascii=False)}

[SHAP ì¤‘ìš” ìš”ì¸ Top 5]
- {json.dumps(shap_top_for_llm, ensure_ascii=False)}

[ì…ë ¥ ë°ì´í„°(ìš”ì•½)]
- ì¼ë¶€ ì£¼ìš” ìˆ˜ì¹˜: {json.dumps({k: patient_input[k] for k in ['AGE','BMI','SPO2','MAP','HR','RR','GCS','PH','PACO2','PAO2','HCO3','LACTATE','FIO2','PEEP','PPLAT','TV'] if k in patient_input}, ensure_ascii=False)}

[ì‘ì„± ì§€ì¹¨]
- í†¤: 
## ë ˆí¬íŠ¸ ì‘ì„± ì§€ì¹¨
**ëª©ì **: ë³´í˜¸ìê°€ ë°œê´€(ì¸ê³µí˜¸í¡ê¸° íŠœë¸Œ ì œê±°) ê²°ì •ì„ ë‚´ë¦¬ëŠ” ë° ë„ì›€ì´ ë˜ëŠ” ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
**í†¤ & ìŠ¤íƒ€ì¼**:
- ë”°ëœ»í•˜ê³  ê³µê°ì ì¸ ì–´ì¡°ë¥¼ ìœ ì§€í•˜ì„¸ìš”
- ë³´í˜¸ìì˜ ë¶ˆì•ˆê°ì„ ì´í•´í•˜ë©´ì„œë„ ì •í™•í•œ ì •ë³´ë¥¼ ì „ë‹¬í•˜ì„¸ìš”
- ì˜í•™ì  ì „ë¬¸ì„±ê³¼ ì¸ê°„ë¯¸ë¥¼ ê· í˜•ìˆê²Œ í‘œí˜„í•˜ì„¸ìš”
**ìš©ì–´ ì„ íƒ**:
- ì „ë¬¸ ì˜ë£Œ ìš©ì–´ëŠ” ì¼ë°˜ì¸ì´ ì´í•´í•˜ê¸° ì‰¬ìš´ í‘œí˜„ìœ¼ë¡œ ë°”ê¿”ì£¼ì„¸ìš”
  ì˜ˆ: "ë°œê´€/ì‚½ê´€" â†’ "í˜¸í¡ê´€ ì œê±°", "ì¸ê³µí˜¸í¡ê¸° íŠœë¸Œ ì œê±°"
  ì˜ˆ: "SPO2" â†’ "í˜ˆì¤‘ ì‚°ì†Œí¬í™”ë„" ë˜ëŠ” "ì‚°ì†Œ ìˆ˜ì¹˜"
  ì˜ˆ: "BMI" â†’ "ì²´ì§ˆëŸ‰ì§€ìˆ˜" ë˜ëŠ” "ë¹„ë§Œë„"
- Feature ì´ë¦„(ì˜ì–´ ë˜ëŠ” ì „ë¬¸ìš©ì–´)ì€ í•œê¸€ë¡œ ì˜ì—­í•˜ì—¬ ì„¤ëª…í•˜ì„¸ìš”
**ì„¤ëª… ë°©ì‹**:
- í™•ë¥  ìˆ˜ì¹˜ë¥¼ êµ¬ì²´ì ì¸ ì˜ˆì‹œë‚˜ ë¹„ìœ ë¡œ ì‰½ê²Œ ì„¤ëª…í•˜ì„¸ìš”
- ìœ„í—˜ ìš”ì¸ì´ ì™œ ì¤‘ìš”í•œì§€ ë³´í˜¸ì ì…ì¥ì—ì„œ ì„¤ëª…í•˜ì„¸ìš”
- ì˜ë£Œì§„ì˜ ëª¨ë‹ˆí„°ë§ê³¼ ì „ë¬¸ì  íŒë‹¨ì´ ì¤‘ìš”í•¨ì„ ê°•ì¡°í•˜ì„¸ìš”
## ë ˆí¬íŠ¸ êµ¬ì„± (ë‹¤ìŒ ìˆœì„œë¡œ ì‘ì„±)
1. **ì¸ì‚¬ ë° ì†Œê°œ** (2-3ë¬¸ì¥)
   - ë”°ëœ»í•œ ì¸ì‚¬ì™€ ë ˆí¬íŠ¸ì˜ ëª©ì  ì„¤ëª…
2. **í™˜ì ìƒíƒœ ìš”ì•½** (3-4ë¬¸ì¥)
   - ì œê³µëœ í™˜ì ì •ë³´ë¥¼ ì¼ë°˜ì¸ì´ ì´í•´í•  ìˆ˜ ìˆëŠ” ë°©ì‹ìœ¼ë¡œ ìš”ì•½
   - ê° ìˆ˜ì¹˜ê°€ ì •ìƒ ë²”ìœ„ì¸ì§€, ì£¼ì˜ê°€ í•„ìš”í•œì§€ ê°„ë‹¨íˆ ì„¤ëª…
3. **AI ì˜ˆì¸¡ ê²°ê³¼ í•´ì„** (4-5ë¬¸ì¥)
   - ì‹¤íŒ¨ í™•ë¥ ì´ ì˜ë¯¸í•˜ëŠ” ë°”ë¥¼ ì‰½ê²Œ ì„¤ëª…
   - ì´ í™•ë¥ ì´ ë†’ì€ì§€ ë‚®ì€ì§€ ë§¥ë½ ì œê³µ
   - ì˜ˆì¸¡ì´ ì ˆëŒ€ì ì´ ì•„ë‹Œ ì°¸ê³ ìë£Œì„ì„ ëª…ì‹œ
4. **ì£¼ìš” ìœ„í—˜ ìš”ì¸ ìƒì„¸ ì„¤ëª…** (ê° ìš”ì¸ë‹¹ 2-3ë¬¸ì¥)
   - SHAP top ìš”ì¸ 3-5ê°œ ìœ„í—˜ ìš”ì¸ì„ ì„ íƒí•˜ì—¬ ì„¤ëª…
   - ê° ìš”ì¸ì´ ì™œ ë°œê´€ ì„±ê³µ/ì‹¤íŒ¨ì— ì˜í–¥ì„ ë¯¸ì¹˜ëŠ”ì§€ ì„¤ëª…
   - Feature ì´ë¦„ì„ ë³´í˜¸ìê°€ ì´í•´í•  ìˆ˜ ìˆëŠ” ìš©ì–´ë¡œ ë³€í™˜
5. **ë§ˆë¬´ë¦¬ ë©”ì‹œì§€** (2ë¬¸ì¥)
   - ì•ˆì‹¬ê³¼ ê²©ë ¤ì˜ ë©”ì‹œì§€
   - ì˜ë£Œì§„ì˜ ì „ë¬¸ì„±ì— ëŒ€í•œ ì‹ ë¢° ê°•ì¡°
**ì¤‘ìš”**: ë ˆí¬íŠ¸ëŠ” ìˆœìˆ˜í•œ í•œê¸€ í…ìŠ¤íŠ¸ë¡œë§Œ ì‘ì„±í•˜ê³ , ë§ˆí¬ë‹¤ìš´ ì„œì‹(#, **, - ë“±)ì€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.
ì„¹ì…˜ ì œëª©ì€ [ì„¹ì…˜ëª…] í˜•íƒœë¡œ í‘œì‹œí•˜ì„¸ìš”.

- ì˜¨í†¨ë¡œì§€ì—ì„œ ê°’=1ì¸ í•­ëª©ì€ 'ì´ í™˜ìì—ê²Œ ì‹¤ì œë¡œ ê´€ì°°ëœ ìœ„í—˜ ì‹ í˜¸'ë¡œ ë°˜ë“œì‹œ ë³¸ë¬¸ì— í¬í•¨í•˜ì„¸ìš”.
- SHAP ìƒìœ„ ìš”ì¸ì€ 'ì™œ ì´ëŸ° ì˜ˆì¸¡ì´ ë‚˜ì™”ëŠ”ì§€' ì„¤ëª…í•˜ëŠ” ê·¼ê±°ë¡œ ì‚¬ìš©í•˜ì„¸ìš”. (ì¦ê°€/ê°ì†Œ ë°©í–¥ì„ ìì—°ìŠ¤ëŸ½ê²Œ ì„œìˆ )
- ê°’=0ì¸ ì˜¨í†¨ë¡œì§€ í•­ëª©ì€ í•„ìš” ì‹œ 'ì™„í™” ìš”ì¸' ë˜ëŠ” 'í˜„ì¬ëŠ” í•´ë‹¹ ì—†ìŒ'ìœ¼ë¡œ ê°„ë‹¨íˆ ì–¸ê¸‰í•´ë„ ë©ë‹ˆë‹¤.
- í™•ë¥  ìˆ˜ì¹˜ëŠ” ë¹„ìœ /ì‚¬ë¡€ë¡œ ì‰½ê²Œ ì„¤ëª…í•˜ë˜, ì ˆëŒ€ì ì¸ ì§„ë‹¨ì´ ì•„ë‹˜ì„ ë¶„ëª…íˆ í•˜ì„¸ìš”.
- ì „ë¬¸ìš©ì–´ëŠ” ì‰¬ìš´ ë§ë¡œ í’€ì–´ì„œ ì„¤ëª…í•˜ì„¸ìš”.
- ë§ˆí¬ë‹¤ìš´ ê¸ˆì§€, ì„¹ì…˜ ì œëª©ì€ [ì„¹ì…˜ëª…] í˜•íƒœ.
- ë¶„ëŸ‰: 8~14ë¬¸ì¥ ì •ë„.
"""
    resp = client.chat.completions.create(
        model=FIXED_GENERATION_MODEL,
        messages=[
            {"role":"system","content":"ë‹¹ì‹ ì€ ì˜ë£Œ ì •ë³´ë¥¼ ì¼ë°˜ì¸ì´ ì´í•´í•˜ê¸° ì‰½ê²Œ ì „ë‹¬í•˜ëŠ” ì˜ë£Œ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
            {"role":"user","content":prompt}
        ],
        temperature=0.5
    )

    body = resp.choices[0].message.content.strip()
    header = f"{'='*60}\nê¸°ê³„í™˜ê¸° ë°œê´€ ì•ˆë‚´ë¬¸\n{'='*60}\n\nìƒì„± ì¼ì‹œ: {datetime.now().strftime('%Yë…„ %mì›” %dì¼ %H:%M')}\n\n"
    footer = f"\n\n{'='*60}\në³¸ ì•ˆë‚´ë¬¸ì€ AI ê¸°ë°˜ ì˜ˆì¸¡ ì‹œìŠ¤í…œì„ í™œìš©í•˜ì—¬ ì‘ì„±ë˜ì—ˆìŠµë‹ˆë‹¤.\nìµœì¢… ì˜ë£Œ ê²°ì •ì€ ë‹´ë‹¹ ì˜ë£Œì§„ì˜ ì¢…í•©ì ì¸ íŒë‹¨ì— ë”°ë¼ ì´ë£¨ì–´ì§‘ë‹ˆë‹¤.\nê¶ê¸ˆí•œ ì ì´ë‚˜ ìš°ë ¤ì‚¬í•­ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“  ì˜ë£Œì§„ì—ê²Œ ë¬¸ì˜í•´ ì£¼ì„¸ìš”.\n{'='*60}\n"
    return header + body + footer

# -------------------------------
# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
# -------------------------------
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []  # [{role, content}]
if "memory" not in st.session_state:
    st.session_state.memory = {}        # ìµœê·¼ ì˜ˆì¸¡ ì»¨í…ìŠ¤íŠ¸ ì €ì¥

# -------------------------------
# ë©”ì¸ UI
# -------------------------------
st.title("Extubation Prediction Demo (Streamlit)")

# (2) ì¼€ì´ìŠ¤ ì„ íƒ â†’ í¼ ìë™ ì±„ìš°ê¸°
st.subheader("1) ì˜ˆì‹œ ì¼€ì´ìŠ¤ ì„ íƒ")
selected_case = st.selectbox("ì˜ˆì‹œ ì¼€ì´ìŠ¤", list(EXAMPLE_CASES.keys()), index=0)
case_vals = EXAMPLE_CASES[selected_case]

# í¼ ì…ë ¥ê°’ì„ ì„¸ì…˜ì— ë°˜ì˜
for k in REQUIRED_FEATURES:
    if f"val_{k}" not in st.session_state:
        st.session_state[f"val_{k}"] = case_vals.get(k, np.nan)

# ì¼€ì´ìŠ¤ ì„ íƒì´ ë°”ë€Œë©´ í•´ë‹¹ ê°’ìœ¼ë¡œ ì´ˆê¸°í™”
def apply_case(vals: dict):
    for k, v in vals.items():
        st.session_state[f"val_{k}"] = v

if st.button("ì´ ì¼€ì´ìŠ¤ ê°’ ë¶ˆëŸ¬ì˜¤ê¸°"):
    apply_case(EXAMPLE_CASES[selected_case])
    st.success(f"{selected_case} ê°’ì´ ì…ë ¥ í¼ì— ë°˜ì˜ë˜ì—ˆìŠµë‹ˆë‹¤.")

# ì…ë ¥ í¼
st.subheader("2) í™˜ì ì…ë ¥")
colA, colB, colC, colD, colE = st.columns(5)

with colA:
    st.session_state["val_AGE"] = st.number_input("AGE", 0, 120, int(st.session_state["val_AGE"]))
    st.session_state["val_SEX"] = st.selectbox("SEX (0=female,1=male)", [0,1], index=int(st.session_state["val_SEX"]))
    st.session_state["val_BMI"] = st.number_input("BMI", 0.0, 80.0, float(st.session_state["val_BMI"]))
    st.session_state["val_VENT_DUR"] = st.number_input("VENT_DUR (hr)", 0.0, 1000.0, float(st.session_state["val_VENT_DUR"]))
    st.session_state["val_CHF"] = st.selectbox("CHF", [0,1], index=int(st.session_state["val_CHF"]))
    st.session_state["val_CVD"] = st.selectbox("CVD", [0,1], index=int(st.session_state["val_CVD"]))
    st.session_state["val_CPD"] = st.selectbox("CPD", [0,1], index=int(st.session_state["val_CPD"]))
    st.session_state["val_CKD"] = st.selectbox("CKD", [0,1], index=int(st.session_state["val_CKD"]))

with colB:
    st.session_state["val_CLD"] = st.selectbox("CLD", [0,1], index=int(st.session_state["val_CLD"]))
    st.session_state["val_DM"] = st.selectbox("DM", [0,1], index=int(st.session_state["val_DM"]))
    st.session_state["val_ECMO"] = st.selectbox("ECMO", [0,1], index=int(st.session_state["val_ECMO"]))
    st.session_state["val_CRRT"] = st.selectbox("CRRT", [0,1], index=int(st.session_state["val_CRRT"]))
    st.session_state["val_MAP"] = st.number_input("MAP", 0.0, 200.0, float(st.session_state["val_MAP"]))
    st.session_state["val_HR"] = st.number_input("HR", 0.0, 220.0, float(st.session_state["val_HR"]))
    st.session_state["val_RR"] = st.number_input("RR", 0.0, 80.0, float(st.session_state["val_RR"]))
    st.session_state["val_BT"] = st.number_input("BT (Â°C)", value=float(case_vals.get("BT", 36.5)))

with colC:
    st.session_state["val_SPO2"] = st.number_input("SPO2 (%)", 0.0, 100.0, float(st.session_state["val_SPO2"]))
    st.session_state["val_GCS"] = st.number_input("GCS", 3.0, 15.0, float(st.session_state["val_GCS"]))
    st.session_state["val_PH"] = st.number_input("pH", 6.8, 7.8, float(st.session_state["val_PH"]), step=0.01)
    st.session_state["val_PACO2"] = st.number_input("PaCO2", 10.0, 120.0, float(st.session_state["val_PACO2"]))
    st.session_state["val_PAO2"] = st.number_input("PaO2", 10.0, 600.0, float(st.session_state["val_PAO2"]))
    st.session_state["val_HCO3"] = st.number_input("HCO3-", 5.0, 45.0, float(st.session_state["val_HCO3"]))
    st.session_state["val_LACTATE"] = st.number_input("Lactate", 0.0, 20.0, float(st.session_state["val_LACTATE"]))

with colD:
    st.session_state["val_WBC"] = st.number_input("WBC", 0.0, 100.0, float(st.session_state["val_WBC"]))
    st.session_state["val_HB"] = st.number_input("Hb", 0.0, 25.0, float(st.session_state["val_HB"]))
    st.session_state["val_PLT"] = st.number_input("PLT", 0.0, 1000.0, float(st.session_state["val_PLT"]))
    st.session_state["val_SODIUM"] = st.number_input("Na", 100.0, 180.0, float(st.session_state["val_SODIUM"]))
    st.session_state["val_POTASSIUM"] = st.number_input("K", 1.5, 8.0, float(st.session_state["val_POTASSIUM"]))
    st.session_state["val_CHLORIDE"] = st.number_input("Cl", 70.0, 140.0, float(st.session_state["val_CHLORIDE"]))
    st.session_state["val_BUN"] = st.number_input("BUN", 0.0, 200.0, float(st.session_state["val_BUN"]))

with colE:
    st.session_state["val_CR"] = st.number_input("Cr", 0.0, 20.0, float(st.session_state["val_CR"]))
    st.session_state["val_PT"] = st.number_input("PT", 5.0, 30.0, float(st.session_state["val_PT"]))
    st.session_state["val_FIO2"] = st.number_input("FiO2 (%)", 21.0, 100.0, float(st.session_state["val_FIO2"]))
    st.session_state["val_PEEP"] = st.number_input("PEEP", 0.0, 30.0, float(st.session_state["val_PEEP"]))
    st.session_state["val_PPLAT"] = st.number_input("Pplat", 0.0, 60.0, float(st.session_state["val_PPLAT"]))
    st.session_state["val_TV"] = st.number_input("TV (mL)", 0.0, 1500.0, float(st.session_state["val_TV"]))

# ì‹¤í–‰ ë²„íŠ¼
st.subheader("3) ì‹¤í–‰")
run = st.button("ì˜ˆì¸¡ ì‹¤í–‰")

if run:
    # ì…ë ¥ ë”•ì…”ë„ˆë¦¬ ë§Œë“¤ê¸°
    patient_input = {k: float(st.session_state[f"val_{k}"]) if not np.isnan(st.session_state[f"val_{k}"]) else np.nan
                     for k in REQUIRED_FEATURES}

    # 1) ì…ë ¥ â†’ DF
    df = _df_from_patient_input(patient_input)

    # 2) ì˜¨í†¨ë¡œì§€ íƒœê¹…
    with st.spinner("ì˜¨í†¨ë¡œì§€ íƒœê¹… ì¤‘..."):
        try:
            if USE_LLM and OPENAI_API_KEY:
                client = build_openai_client()
                ontology_json = llm_tag_ontology(client, df)
            else:
                ontology_json = rule_based_ontology(df)
        except Exception as e:
            st.warning(f"LLM íƒœê¹… ì‹¤íŒ¨. ë£° ê¸°ë°˜ìœ¼ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤. ({e})")
            ontology_json = rule_based_ontology(df)

    feature_df = attach_ontology_features(df.copy(), ontology_json)

    # 3) ëª¨ë¸ ë¡œë“œ & ì˜ˆì¸¡
    with st.spinner("XGBoost ì˜ˆì¸¡ ì¤‘..."):
        try:
            booster = load_xgb_model(FIXED_MODEL_PATH)
            pred = run_xgb_predict(booster, feature_df)
        except Exception as e:
            st.error(f"ì˜ˆì¸¡ ì˜¤ë¥˜: {e}")
            st.stop()

    # 4) SHAP
    with st.spinner("SHAP ê³„ì‚° ì¤‘..."):
        try:
            shap_exp = compute_shap(booster, feature_df)
        except Exception as e:
            st.warning(f"SHAP ê³„ì‚° ì‹¤íŒ¨: {e}")
            shap_exp = {"feature_importance": {}, "top_risk_factors": []}

    # 5) ë ˆí¬íŠ¸
    report_text = None
    if USE_LLM and OPENAI_API_KEY:
        with st.spinner("ì„¤ëª… ë ˆí¬íŠ¸ ìƒì„± ì¤‘..."):
            try:
                client = build_openai_client()
                # â¬‡ï¸ ì˜¨í†¨ë¡œì§€ í•¨ê»˜ ì „ë‹¬
                report_text = llm_generate_report(client, patient_input, pred, shap_exp, ontology_json)
            except Exception as e:
                st.warning(f"ë ˆí¬íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
                report_text = None

    # ê²°ê³¼ í‘œì‹œ
    st.success("ì™„ë£Œ!")

    col1, col2 = st.columns([1,1])
    with col1:
        st.markdown("### ì˜ˆì¸¡ ê²°ê³¼")
        st.metric("ë°œê´€ ì‹¤íŒ¨ í™•ë¥ ", f"{pred['probability']*100:.1f}%")
        st.metric("ì˜ˆì¸¡ í´ë˜ìŠ¤", pred["class_label"])  # â€œì•ˆì „/ìœ„í—˜â€

        st.markdown("### ì˜¨í†¨ë¡œì§€ íƒœê¹… ê²°ê³¼")
        pretty_df = ontology_pretty_table(ontology_json)
        st.dataframe(pretty_df, hide_index=True, use_container_width=True)

    with col2:
        st.markdown("### ìƒìœ„ ìœ„í—˜ ìš”ì¸ (SHAP | ì ˆëŒ€ê°’ Top 5)")
        if "top_risk_factors" in shap_exp and shap_exp["top_risk_factors"]:
            rows = []
            for name, abs_imp in shap_exp["top_risk_factors"]:
                sign = shap_exp["feature_importance"].get(name, 0.0)
                direction = "â†‘ ìœ„í—˜ ì¦ê°€" if sign > 0 else "â†“ ìœ„í—˜ ê°ì†Œ"
                rows.append({"feature": name, "abs_importance": round(abs_imp, 5), "direction": direction})
            st.dataframe(pd.DataFrame(rows), hide_index=True, use_container_width=True)
        else:
            st.write("ê³„ì‚°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    # (5) ë³´í˜¸ì ì„¤ëª…ìš© ë ˆí¬íŠ¸: í¸ì§‘ ê°€ëŠ¥í•œ í…ìŠ¤íŠ¸ ë°•ìŠ¤
    st.markdown("### ë³´í˜¸ì ì„¤ëª…ìš© ë ˆí¬íŠ¸")

    if report_text:
        # ìµœì´ˆ ìƒì„± ì‹œ ì„¸ì…˜ ìƒíƒœì— ì €ì¥
        if "report_text" not in st.session_state or not st.session_state.get("report_text"):
            st.session_state.report_text = report_text

        # í¸ì§‘ ê°€ëŠ¥í•œ í…ìŠ¤íŠ¸ ì˜ì—­
        st.session_state.report_text = st.text_area(
            "ìƒì„±ëœ ë ˆí¬íŠ¸ (í¸ì§‘ ê°€ëŠ¥)",
            value=st.session_state.report_text,
            height=420,
            help="í•„ìš” ì‹œ ë¬¸êµ¬ë¥¼ ìˆ˜ì •í•˜ì—¬ ë³´í˜¸ì ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ì— í™œìš©í•˜ì„¸ìš”."
        )

        # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ (ì„ íƒ)
        st.download_button(
            label="ë ˆí¬íŠ¸ .txt ë‹¤ìš´ë¡œë“œ",
            data=st.session_state.report_text,
            file_name=f"extubation_report_{datetime.now().strftime('%Y%m%d_%H%M')}.txt",
            mime="text/plain",
            use_container_width=True
        )
    else:
        st.info("ë ˆí¬íŠ¸ê°€ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ìƒë‹¨ì—ì„œ ì˜ˆì¸¡ì„ ì‹¤í–‰í•˜ë©´ ìë™ìœ¼ë¡œ ìƒì„±ë©ë‹ˆë‹¤.")

    st.markdown("### ëª¨ë¸ ì…ë ¥ ì „ì²´ Feature (ì¶”ë¡  ì‹œ ì‚¬ìš©)")
    st.dataframe(feature_df, use_container_width=True)

    # ì±„íŒ… ë©”ëª¨ë¦¬ì— ì €ì¥í•  ì»¨í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸
    st.session_state.memory = {
        "timestamp": datetime.now().isoformat(timespec="seconds"),
        "selected_case": selected_case,
        "patient_input": patient_input,
        "prediction": pred,
        "shap_top": shap_exp.get("top_risk_factors", []),
    }

# -------------------------------
# ì‚¬ì´ë“œë°”: ì±„íŒ… (ëª¨ë¸/ê²½ë¡œ ì…ë ¥ ëŒ€ì‹ )
# -------------------------------
with st.sidebar:
    st.header("ğŸ’¬ í™˜ì ë³´í˜¸ìë¥¼ ìœ„í•œ ì±—ë´‡ ì–´ì‹œìŠ¤í„´íŠ¸")
    if OPENAI_API_KEY is None:
        st.caption("OpenAI í‚¤ê°€ ì—†ì–´ì„œ ì±„íŒ…ì€ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤. (Secretsì— OPENAI_API_KEY ì¶”ê°€)")
    else:
        # ìµœê·¼ ì˜ˆì¸¡ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì‹œìŠ¤í…œ ë©”ì‹œì§€ë¡œ ì£¼ì…
        context_blob = json.dumps(st.session_state.memory, ensure_ascii=False, indent=2) if st.session_state.memory else "ìµœê·¼ ì˜ˆì¸¡ ì»¨í…ìŠ¤íŠ¸ ì—†ìŒ."
        system_msg = (
            "ë‹¹ì‹ ì€ ì¤‘í™˜ìì‹¤ì— ì…ì‹¤í•œ í™˜ì ë³´í˜¸ìë¥¼ ëŒ€í•˜ëŠ” ì˜ë£Œì¸ì…ë‹ˆë‹¤. "
            "ì•„ë˜ 'ìµœê·¼ ì˜ˆì¸¡ ì»¨í…ìŠ¤íŠ¸'ë¥¼ ì°¸ê³ í•˜ì—¬ ì¹œì ˆí•˜ê³  ì‰½ê²Œ ë‹µë³€í•˜ì„¸ìš”. ì˜ë£Œì¸ì´ ì•„ë‹Œ ì‚¬ëŒë“¤ë„ ì•Œì•„ë“¤ì„ ìˆ˜ ìˆë„ë¡ ì„¤ëª…í•˜ì„¸ìš”. \n\n"
            f"[ìµœê·¼ ì˜ˆì¸¡ ì»¨í…ìŠ¤íŠ¸]\n{context_blob}"
        )

        # ê¸°ì¡´ ëŒ€í™” í‘œì‹œ
        for m in st.session_state.chat_history:
            with st.chat_message(m["role"]):
                st.markdown(m["content"])

        user_msg = st.chat_input("ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”")
        if user_msg:
            st.session_state.chat_history.append({"role":"user","content":user_msg})
            with st.chat_message("user"):
                st.markdown(user_msg)

            try:
                client = build_openai_client()
                messages = [{"role":"system","content":system_msg}] + st.session_state.chat_history[-20:]  # ìµœê·¼ 20í„´
                resp = client.chat.completions.create(
                    model=CHAT_MODEL,
                    messages=messages,
                    temperature=0.3
                )
                bot_text = resp.choices[0].message.content.strip()
            except Exception as e:
                bot_text = f"(ì˜¤ë¥˜) {e}"

            st.session_state.chat_history.append({"role":"assistant","content":bot_text})
            with st.chat_message("assistant"):
                st.markdown(bot_text)